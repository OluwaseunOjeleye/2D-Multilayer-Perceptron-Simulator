Layer 0
2
Layer 1
6
Layer 2
3
Layer 3
6
Layer 4
3

Hidden Layer Activation Function:
sigmoid

Output Layer Activation Function:
sigmoid

Learning Rate:
0.5

Weight 0
6
2
-2.47227 5.15277 
1.51244 -3.19005 
1.61115 -1.97069 
6.8787 3.52988 
-2.00404 7.32645 
1.06012 -4.92712 

Weight 1
3
6
-1.68221 -0.425693 -1.84262 -4.59735 -2.65389 -2.01054 
-0.46177 -2.57816 -2.62037 5.58854 -0.59269 -3.92559 
-3.85344 1.43065 0.38601 -5.14867 -4.6062 1.58519 

Weight 2
6
3
1.68295 -1.7017 7.25312 
-5.19832 -1.06867 -6.7425 
-4.7675 -4.83537 7.02947 
-3.24272 -4.01576 -0.740849 
-0.717598 -7.21626 1.51342 
0.137243 -0.383516 1.25191 

Weight 3
3
6
3.24539 3.25587 -3.19249 -3.0752 3.16686 0.094006 
-0.0513447 -3.24903 -0.00339198 3.93298 -3.2569 0.428406 
-3.34545 -0.000685101 3.29359 -0.273758 0.0819745 -0.0396481 

Bias 0
6
1
4.75417 
2.48099 
4.77015 
-1.62461 
5.52128 
3.47128 

Bias 1
3
1
0.0317859 
-0.590196 
-0.771738 

Bias 2
6
1
0.975174 
4.93295 
1.71597 
4.52821 
2.86161 
3.46475 

Bias 3
3
1
2.90497 
2.14939 
0.285683 

Samples:
25
-246 238 0
-259 216 0
-259 216 0
-241 218 0
-229 230 0
208 -199 0
194 -218 0
215 -222 0
226 -202 0
-35 209 1
-55 202 1
-39 191 1
-22 188 1
15 -136 1
16 -152 1
29 -151 1
26 -127 1
120 -23 2
109 -27 2
122 -43 2
141 -31 2
-214 46 2
-217 34 2
-200 30 2
-192 41 2
