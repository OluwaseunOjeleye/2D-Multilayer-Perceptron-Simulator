Layer 0
2
Layer 1
8
Layer 2
3

Hidden Layer Activation Function:
sigmoid

Output Layer Activation Function:
sigmoid

Learning Rate:
0.5

Weight 0
8
2
-1.80671 2.63926 
0.937959 3.06691 
0.251596 0.152863 
0.060538 0.0761571 
-1.27943 -1.58788 
0.167498 0.0915332 
0.0345736 -2.39112 
1.54003 -2.78048 

Weight 1
3
8
-2.81053 1.49689 1.19541 0.217206 0.659241 0.297504 0.28577 -3.1921 
0.958894 -3.30848 0.315513 0.585804 -1.61347 0.38865 -1.69236 0.923166 
2.29425 2.2371 -1.6342 -1.35453 1.32108 -1.2416 2.03986 2.17403 

Bias 0
8
1
1.99666 
2.72968 
1.71478 
1.47502 
2.64089 
1.31012 
2.02396 
3.30988 

Bias 1
3
1
1.83998 
2.79383 
-0.588617 

Samples:
8
-166 137 0
145 -135 0
67 162 1
-137 -161 1
-51 44 2
6 45 2
-171 9 2
-65 -37 2
