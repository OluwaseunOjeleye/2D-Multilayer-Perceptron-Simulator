Layer 0
2
Layer 1
8
Layer 2
3

Hidden Layer Activation Function:
sigmoid

Output Layer Activation Function:
sigmoid

Learning Rate:
0.5

Weight 0
8
2
5.39398 2.06853 
3.01505 6.58954 
3.01635 0.0860086 
-0.430872 6.25354 
-4.78036 2.73419 
-0.175113 -4.60639 
-0.0524408 1.04528 
-0.982237 -1.46801 

Weight 1
3
8
-0.236595 -1.17621 0.268122 4.82745 -0.135939 3.91157 0.163181 -0.445869 
-2.24282 3.50857 -1.08529 -3.94292 -2.57964 -2.25046 -0.243207 -0.15747 
2.95023 -3.05701 0.339574 -0.219051 2.90923 -0.591738 0.019988 0.025443 

Bias 0
8
1
-1.96516 
2.37122 
-0.320403 
2.15194 
0.274032 
2.76887 
-0.927249 
-0.58009 

Bias 1
3
1
-0.174951 
1.39354 
3.0783 

Samples:
9
-157 139 0
2 136 0
166 134 0
169 18 1
4 -90 1
-161 247 1
-153 -33 2
5 243 2
172 -94 2
