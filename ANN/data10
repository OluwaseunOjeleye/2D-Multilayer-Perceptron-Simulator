Layer 0
2
Layer 1
8
Layer 2
3

Hidden Layer Activation Function:
sigmoid

Output Layer Activation Function:
sigmoid

Learning Rate:
0.1

Weight 0
8
2
-2.22506 1.54607 
1.21572 1.72707 
0.360274 -0.141599 
-0.317844 3.57513 
1.5004 -3.49041 
1.03744 -0.476575 
-0.00487755 0.0675675 
-1.29079 -2.46795 

Weight 1
3
8
-2.16613 1.46998 -0.301596 -1.03641 -3.14262 -0.434448 0.852844 1.96717 
2.19318 -1.53758 0.474391 -2.08812 0.128236 0.979707 1.27345 -3.25422 
0.0803926 0.523224 -1.07948 3.17711 3.51027 -0.612842 -1.09626 1.45871 

Bias 0
8
1
1.49687 
2.24095 
1.39772 
3.19215 
3.2609 
1.00207 
1.86778 
2.82954 

Bias 1
3
1
2.01697 
2.50482 
-0.532881 

Samples:
8
-166 137 0
145 -135 0
67 162 1
-137 -161 1
-51 44 2
6 45 2
-171 9 2
-65 -37 2
